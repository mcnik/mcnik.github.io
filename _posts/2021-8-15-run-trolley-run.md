---
layout: post
title: Why Must The Trolley Run?
---

You are out on your own. You are waiting for the train to pass so you can get across the street and continue having a good time. You have always been a fan of trains so you can't wait to see what this one looks like[^1]. A prickling sensation on your neck tells you that something is wrong. You make a mental note to see a neck doctor. Looking around, you notice there are five people tied to the tracks. A trolley, seemingly self-propelled, suddenly appears and it is headed straight for them. Surprisingly, you see another person tied to a different parallel set of tracks. You look around and spot a lever right next to you. The lever is conveniently labeled "pulling this lever will save the five people and kill the one person on the other track." 


##### Doing Nothing


> You can choose a ready guide in some celestial voice / If you choose not to decide, you still have made a choice / You can choose from phantom fears and kindness that can kill / I will choose a path that's clear, I will choose [Freewill](https://www.youtube.com/watch?v=qn6GreRpPpU)

First of all, what kind of sicko goes around tying people to tracks? Is it one person or an entire cabal? <br/><br/>
How did they find, abduct, and tie up 6 people? <br/><br/>
Are there passengers on the trolley? Why aren't they doing anything? <br/><br/>
Did no one else see this happen? <br/><br/>
Why are you here? Did you also get abducted by them? <br/><br/>
Do you live with the aftermath of events for the rest of your life while they who are really responsible go free to continue running thought experiments? <br/><br/>
Do you remember what you were doing before you ended up here? <br/><br/>
Do you have any agency outside of this ethical conundrum? Isn't there any easier way to teach the difference between utilitarianism and deontological approaches? <br/><br/>

These are some of the questions that _don't_ appear in your mind because your mind is already occupied by "the big one": What is the right thing to do? 

<blockquote><p lang="en" dir="ltr">If I worked at the trolley operator contracting agency, I would simply not take that trolley operator job. I don&#39;t see the problem.</p><a href="https://twitter.com/doppelhanger/status/1280757650645385216">July 8, 2020</a></blockquote>

There is only one possible way not to lose a game: never play it. By choosing to sacrifice anyone, you are ultimately making a choice to participate in this obtuse game. By choosing to participate, you are accepting the rules laid down by the invisible Jigsaw-style ethicist-serial killer who designed the game in the first place. 


##### A Self-driving Trolley Runs Through It


The above game relies on the fundamental assumption that a human life is the ultimate measure of any decision-making system. If people weren't going to die, the game wouldn't matter. The biggest challenge when driving a car is similar: not killing a human being&mdash;you included. 

So, making a self-driving car is about making a decision-making system that understands that it must not kill. Imagine a dark stormy sky on a rainy night and a self-driving car repeating to itself several times, "Must Not Kill" as it navigates a city street. A self-driving car trying really hard not to obey its programming&mdash;the one telling it to go from point A to point B[^2]. 

Silicon Valley and the culture of innovation it prides itself on and capitalism has an impact on human lives. Usually, this impact is abstracted into a web/mobile interface and it is easier to ignore the very human cost of decision-making systems. With self-driving cars, the impact can be quite direct and literal[^3].

As is often the case, once you put a system into the real world, the real world&mdash;in all its glorious complexity&mdash;interacts with it. The layers of abstraction provided by software are not as useful when you put people and nature into the mix. There have been incredible advances in the underlying technology but to navigate a typical city street, you need a lot more than just image recognition. [Uber gave up](https://www.cnn.com/2020/12/07/cars/uber-sells-self-driving/index.html). Some ["didnâ€™t expect it to be so hard"](https://twitter.com/elonmusk/status/1411280212470366213). Others have been [cautious](https://www.verdict.co.uk/the-long-winding-road-to-self-driving-cars/) and [measured](https://www.reuters.com/business/autos-transportation/tesla-tells-regulator-that-full-self-driving-cars-may-not-be-achieved-by-year-2021-05-07/). 

Would self-driving cars be more "successful" if they claimed to solve the problem of car-involved fatalities[^4]?


##### Acceptable Costs


<blockquote><p lang="en" dir="ltr">The trolley problem is just another way for the big Corporation to shift responsibility to the Individual in the name of &quot;ethics&quot;.</p><a href="https://twitter.com/doppelhanger/status/1398294128039927810">May 28, 2021</a></blockquote>

One could argue that society must not allow the self-driving trolley to run unchecked[^5]. The Trolley Company profits by getting us all to accept the risk of a few people being run over. The Trolley Company is banking on selling a lot of these trolleys (not to mention, monetizing the self-driving AI) at the cost of a few people living with the trauma of pulling the lever. 

One argument goes that people are bad drivers so maybe it is in society's interest to find a better alternative. Self-driving technology, in itself, could be fairly useful if it were an infrastructure layer that public transport could use. Let us assume that we all agree that having a better driver would be helpful for a number of reasons and we are willing to accept the risks/trade-offs of having a dedicated track where a self-driving trolley trundles regularly. Saving a few lives in the long term is more valuable than lives in the short term[^6]. 

If we accept that the future is inevitable, we can start thinking about things to do while we wait. Because a future with self-driving vehicles is inevitable. Moving things is a much bigger market than moving people so [self-driving trucks](https://www.wired.com/story/trucks-move-past-cars-road-autonomy/) might arrive much before self-driving cars. Some of the same companies betting on self-driving cars are now betting on self-driving trucks. 

I think making AI-driven cars look different from human-driven cars is a good first step[^7]. You can focus on the algorithm doing the driving by asking for [Fairness, Accountability, and Transparency](https://www.sigcas.org/events/conferences/) from the creators of the algorithm and prevent them from shirking responsibility. This last thing is relevant to all applications of Machine Learning and automated decision-making systems.


##### Back to the Metaphorical Future


If your Trolley Engineering team is set the goal of achieving maximum operational efficiency at hitting the trolley switch, they will work on that problem. How will they measure their success? By the number of decisions made to switch the trolley. Not by the number of people saved or the number of runaway trolleys stopped. 

Why must we accept that the individual needs to pull the switch? Why is there no switch to stop the runaway trolley? Even in an exaggerated metaphorical interpretation, like this one, the question must be asked. Framing a decision here as a binary (save or kill people) causes us to view it as an unavoidable choice. "How do I stop the trolley?" is the question to ask. 

Maybe, we stop all trolley runs and make sure our self-driving AI understands that it is part of a larger, complex social system and not just responsible for getting from point A to point B. You might save five people or you might save one person now but you must make sure that no one else has to ever make this terrible choice.

<div style="text-align:center"> <img src="https://user-images.githubusercontent.com/7941357/128569122-8f2ab756-34ba-4a61-8eef-bc71659b72f7.png" alt="waving at the trolley"></div>
<br/><br/>

---

<br/><br/>

[^1]: The "trolley" looks a lot like a [San Francisco cable car](https://en.wikipedia.org/wiki/San_Francisco_cable_car_system#Cars) so we will assume it is one.

[^2]: A self-driving car trying not to obey its programming is basically [I WILL NOT OBEY THE VOICES IN MY HEAD](http://bartsblackboard.com/i-will-not-obey-the-voices-in-my-head/season-11/625/).

[^3]: [How different is the airplane autopilot from a self-driving car?](https://www.aitrends.com/ai-insider/airplane-autopilot-systems-self-driving-car-ai/)

[^4]: The 32,479 traffic fatalities in 2011 were the lowest in 62 years, [since 1949](https://en.wikipedia.org/wiki/Motor_vehicle_fatality_rate_in_U.S._by_year#/media/File:US_traffic_deaths_per_VMT,_VMT,_per_capita,_and_total_annual_deaths.png).

[^5]: The trolley is a metaphor for capitalism.

[^6]: Not very different from the "Let's kill baby Hitler!" argument but is it different from the "Just get the damn vaccine already" argument?

[^7]: I personally like the way [Cruise cars](https://en.wikipedia.org/wiki/Cruise_(autonomous_vehicle)#/media/File:Cruise_Automation_Bolt_EV_third_generation_in_San_Francisco.jpg) look. They have externally visible sensors and indicate clearly that this vehicle is different from others. I haven't seen one of these yet but they have also been testing cars without human drivers since [December 2020](https://www.sfchronicle.com/business/article/Cruise-deploys-true-robot-cars-in-S-F-no-15788555.php). They also have a [driverless taxi](https://www.theverge.com/2020/1/21/21075977/cruise-driverless-car-gm-no-steering-wheel-pedals-ev-exclusive-first-look) which has been built to be autonomous as opposed to retrofitted for AI-driving. This future seems inevitable considering that Cruise expects mass production of the shuttle to begin in 2023. In the meantime, why don't we require AI-driven cars to look like something H. R. Giger designed? Just indicate visually that a person is not making decisions. I'm sure this has an implication on the training of the algorithm but I think that could be an acceptable short-term tradeoff.
